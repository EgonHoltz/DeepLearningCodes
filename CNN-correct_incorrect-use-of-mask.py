# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gbaeO6ZoJEfYS0Ary9gJCTW13FMaps8W

MEIW - Deep Learning Aplicado 


Projeto: Trabalho 2

Descrição: A partir de imagens, definir se há o uso correcto ou não de máscada cirugica

Autor: Egon Holtz


---
"""

import os, shutil, zipfile

#Download the dataset from google drive (Right use of masks only)
if os.path.exists('./CMFD.zip') == False:
  !gdown --id 17-FCstm8Fz3bDzFgTmOWHa_c39lTR_1P

#Extract all files to tmp file
if os.path.exists('./tmp/CMFD') == False:
  zip_ref = zipfile.ZipFile("./CMFD.zip", 'r')
  zip_ref.extractall("./tmp/CMFD")
  zip_ref.close()

original_dataset_dir_correct = './tmp/CMFD'

#Move all files from folders inside of ./tmp/CMFD/0i000 to ./tmp/CMFD
fnames = ['{:0>2d}'.format(i)+'000' for i in range(7)]
for fname in fnames:
  src = os.path.join(original_dataset_dir_correct, fname)
  dst = original_dataset_dir_correct
  file_names = os.listdir(src)
  for file_name in file_names:
    shutil.move(os.path.join(src, file_name), dst)
  if os.path.exists('src') == True:
    shutil.rmtree(src)

#Shrink use of space
fnames = ['{:0>2d}'.format(i)+'000' for i in range(8,35)]
for fname in fnames:
  src = os.path.join(original_dataset_dir_correct, fname)
  if os.path.exists(src) == False:
    continue
  file_names = os.listdir(src)
  for file_name in file_names:
    file_path = os.path.join(src, file_name)
    os.unlink(file_path)
  shutil.rmtree(src)
    
#Donwload the dataset from google drive (Wrong use of masks only)

if os.path.exists('./IMFD.zip') == False:
  !gdown --id 1gjltyD_MnNWcnd56NnjUOizdi39CUEPF

#Extract all files to tmp file
if os.path.exists('./tmp/IMFD') == False:
  zip_ref = zipfile.ZipFile("./IMFD.zip", 'r')
  zip_ref.extractall("./tmp/IMFD")
  zip_ref.close()

original_dataset_dir_incorrect = './tmp/IMFD'

#Move all files from folders inside of ./tmp/IMFD/0i000 to ./tmp/IMFD
fnames = ['{:0>2d}'.format(i)+'000' for i in range(0,35)]
for fname in fnames:
  src = os.path.join(original_dataset_dir_incorrect, fname)
  dst = original_dataset_dir_incorrect
  file_names = os.listdir(src)
  for file_name in file_names:
    shutil.move(os.path.join(src, file_name), dst)
  if os.path.exists('src') == True:
    shutil.rmtree(src)

#Shrink use of space
#fnames = ['{:0>2d}'.format(i)+'000' for i in range(9,35)]
#for fname in fnames:
#  src = os.path.join(original_dataset_dir_incorrect, fname)
#  if os.path.exists(src) == False:
#    continue
##  file_names = os.listdir(src)
#  for file_name in file_names:
##    file_path = os.path.join(src, file_name)
#    os.unlink(file_path)
#  shutil.rmtree(src)

base_dir = './use_masks'
if os.path.exists(base_dir) == False:
  os.mkdir(base_dir)

#Create base folders: train, validation and test
train_dir = os.path.join(base_dir, 'train')
if os.path.exists(train_dir) == False:
  os.mkdir(train_dir)
validation_dir = os.path.join(base_dir, 'validation')
if os.path.exists(validation_dir) == False:
  os.mkdir(validation_dir)
test_dir = os.path.join(base_dir, 'test')
if os.path.exists(test_dir) == False:
  os.mkdir(test_dir)

#Create correct and incorrect use datasets inside each base
validation_correct_dir = os.path.join(validation_dir, 'correct')
if os.path.exists(validation_correct_dir) == False:
  os.mkdir(validation_correct_dir)
validation_incorrect_dir = os.path.join(validation_dir, 'incorrect')
if os.path.exists(validation_incorrect_dir) == False:
  os.mkdir(validation_incorrect_dir)

train_correct_dir = os.path.join(train_dir, 'correct')
if os.path.exists(train_correct_dir) == False:
  os.mkdir(train_correct_dir)
train_incorrect_dir = os.path.join(train_dir, 'incorrect')
if os.path.exists(train_incorrect_dir) == False:
  os.mkdir(train_incorrect_dir)


#Extract from temp folders, the images distributed to created paths

#correct train - 2000
i = 0
image_counter = 0
while True:
  fname = '{:0>5d}_Mask.jpg'.format(i)
  src = os.path.join(original_dataset_dir_correct,fname)
  if os.path.exists(src) == True:
    dst = os.path.join(train_correct_dir, fname)
    shutil.move(src, dst)
    image_counter = image_counter + 1
  i = i+1
  if image_counter >= 2000 or i > 8000:
    print('image_id: {:d} index: {:d}'.format(image_counter,i))
    break

#correct validation - 500
image_counter = 0
while True:
  fname = '{:0>5d}_Mask.jpg'.format(i)
  src = os.path.join(original_dataset_dir_correct,fname)
  if os.path.exists(src) == True:
    dst = os.path.join(validation_correct_dir, fname)
    shutil.move(src, dst)
    image_counter = image_counter + 1
  i = i+1
  if image_counter >= 500 or i > 8000:
    print('image_id: {:d} index: {:d}'.format(image_counter,i))
    break

#correct test - 500
image_counter = 0
image_test = 0
while True:
  fname = '{:0>5d}_Mask.jpg'.format(i)
  src = os.path.join(original_dataset_dir_correct,fname)
  if os.path.exists(src) == True:
    dst = os.path.join(test_dir, '{:0>5d}.jpg'.format(image_test))
    shutil.move(src, dst)
    image_counter = image_counter + 1
    image_test = image_test +1
  i = i+1
  if image_counter >= 500 or i > 8000:
    print('image_id: {:d} index: {:d}'.format(image_counter,i))
    break

#incorrect train - 2000
j = 0
image_counter = 0
while True:
  fnameChin = '{:0>5d}_Mask_Chin.jpg'.format(j)
  srcChin = os.path.join(original_dataset_dir_incorrect,fnameChin)
  fnameMouthChin = '{:0>5d}_Mask_Mouth_Chin.jpg'.format(j)
  srcMouthChin = os.path.join(original_dataset_dir_incorrect,fnameMouthChin)
  if os.path.exists(srcChin) == True:
    dst = os.path.join(train_incorrect_dir, fnameChin)
    shutil.move(srcChin, dst)
    image_counter = image_counter + 1
  elif os.path.exists(srcMouthChin) == True:
    dst = os.path.join(train_incorrect_dir, fnameMouthChin)
    shutil.move(srcMouthChin, dst)
    image_counter = image_counter + 1
  j = j+1
  #We just extracted 35000 incorrect images
  if image_counter >= 2000 or j > 35000:
    print('image_id: {:d} index: {:d}'.format(image_counter,j))
    break

#correct validation - 500
image_counter = 0
while True:
  fnameChin = '{:0>5d}_Mask_Chin.jpg'.format(j)
  srcChin = os.path.join(original_dataset_dir_incorrect,fnameChin)
  fnameMouthChin = '{:0>5d}_Mask_Mouth_Chin.jpg'.format(j)
  srcMouthChin = os.path.join(original_dataset_dir_incorrect,fnameMouthChin)
  if os.path.exists(srcChin) == True:
    dst = os.path.join(validation_incorrect_dir, fnameChin)
    shutil.move(srcChin, dst)
    image_counter = image_counter + 1
  elif os.path.exists(srcMouthChin) == True:
    dst = os.path.join(validation_incorrect_dir, fnameMouthChin)
    shutil.move(srcMouthChin, dst)
    image_counter = image_counter + 1
  j = j+1
  if image_counter >= 500 or j > 35000:
    print('image_id: {:d} index: {:d}'.format(image_counter,j))
    break

#correct test - 500
image_counter = 0
while True:
  fnameChin = '{:0>5d}_Mask_Chin.jpg'.format(j)
  srcChin = os.path.join(original_dataset_dir_incorrect,fnameChin)
  fnameMouthChin = '{:0>5d}_Mask_Mouth_Chin.jpg'.format(j)
  srcMouthChin = os.path.join(original_dataset_dir_incorrect,fnameMouthChin)
  if os.path.exists(srcChin) == True:
    dst = os.path.join(test_dir, '{:0>5d}.jpg'.format(image_test))
    shutil.move(srcChin, dst)
    image_counter = image_counter + 1
    image_test = image_test + 1
  elif os.path.exists(srcMouthChin) == True:
    dst = os.path.join(test_dir, '{:0>5d}.jpg'.format(image_test))
    shutil.move(srcMouthChin, dst)
    image_counter = image_counter + 1
    image_test = image_test + 1
  j = j+1
  if image_counter >= 500 or j > 35000:
    print('image_id: {:d} index: {:d}'.format(image_counter,i))
    break


print('total training correct images:',len(os.listdir(train_correct_dir)))
print('total training incorrect images:',len(os.listdir(train_incorrect_dir)))
print('total validation correct images:',len(os.listdir(validation_correct_dir)))
print('total validation incorrect images:',len(os.listdir(validation_incorrect_dir)))
print('total test images:', len(os.listdir(test_dir)))

"""A utilizar treino de CNN puro no modelo a partir das imagens de trieno

loss: 8.3249e-05

acc: 1.0000

val_loss: 7.3905e-04

val_acc: **1.0000**


---

Tempo de duração de média de 60 minutos
"""


import os
import numpy as np
from keras import layers
from keras import models
from keras.preprocessing.image import ImageDataGenerator 
import matplotlib.pyplot as plt
from tensorflow.keras import optimizers
from keras.preprocessing.image import ImageDataGenerator 

base_dir = './use_masks'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')
test_dir = os.path.join(base_dir, 'test')

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid')) #binary end the network with a single unit

model.summary()

model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(learning_rate=1e-4),metrics=['acc'])



train_datagen = ImageDataGenerator(rescale=1./255) #rescales all images by 1 to 255
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
  train_dir,
  target_size=(150, 150), #Resizes all images to 150 x 150
  batch_size=20,
  class_mode='binary')

validation_generator = test_datagen.flow_from_directory(
  validation_dir,
  target_size=(150, 150),
  batch_size=20,
  class_mode='binary') #binary label because it is a binary_crossentropy

history = model.fit_generator(
  train_generator,
  steps_per_epoch=100,
  epochs=30,
  validation_data=validation_generator,
  validation_steps=50)

#Create graph with accuracy and loss
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc) + 1)
plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

"""Mostra imagens do dataset de treino e informa se o uso da máscara está correto ou não

As imagens mostradas são carregadas de maneira aleatória

"""

from random import randrange
from keras.preprocessing.image import image

for i in range(19):
  fileToTest = test_dir + '/'+ '{:0>5d}.jpg'.format(randrange(999))
  while os.path.exists(fileToTest) == False:
    fileToTest = test_dir + '/'+ '{:0>5d}.jpg'.format(randrange(999))
    print(fileToTest)
  img = image.load_img(fileToTest, target_size=(150,150,3))
  plt.imshow(img)
  plt.show()
  x = image.img_to_array(img)
  x = np.expand_dims(x,axis=0)
  images = np.vstack([x])

  val = model.predict(images)
  if val==0:
    print("Máscara corretamente colocada (Correct use of mask)")
  else:
    print('Máscara incorretamente colocada (Incorrect use of mask)')
  print("-------------------------------------------------")
